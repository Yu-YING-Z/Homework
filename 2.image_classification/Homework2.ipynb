{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e445a-2c22-4461-9c59-37d4b85949d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库和模块\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "# 模拟耗时操作（如数据下载）\n",
    "for i in range(100):\n",
    "    time.sleep(0.1)  # 模拟耗时操作，每次休眠0.1秒\n",
    "    print(f\"当前进度: {i+1}/100\")  # 输出当前进度，显示下载进度\n",
    "\n",
    "# 解压 CIFAR-10 数据集\n",
    "with tarfile.open('cifar-10-python.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall('./data')  # 将压缩文件解压到./data目录\n",
    "\n",
    "print(\"解压完成\")  # 提示解压完成\n",
    "\n",
    "# 定义数据预处理转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为 PyTorch 张量\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 对图像进行标准化\n",
    "])\n",
    "\n",
    "# 加载 CIFAR-10 训练集\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',  # 指定数据集根目录\n",
    "    train=True,     # 表示加载训练集\n",
    "    download=False, # 数据集已经存在，不需要下载\n",
    "    transform=transform # 应用预处理转换\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,       # 加载的训练集\n",
    "    batch_size=4,   # 每次加载4个样本\n",
    "    shuffle=True,   # 在每个训练周期开始时打乱数据顺序\n",
    "    num_workers=2   # 使用两个子进程来加载数据\n",
    ")\n",
    "\n",
    "# 加载 CIFAR-10 测试集\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',  # 指定数据集根目录\n",
    "    train=False,    # 表示加载测试集\n",
    "    download=False, # 数据集已经存在，不需要下载\n",
    "    transform=transform # 应用预处理转换\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,        # 加载的测试集\n",
    "    batch_size=4,   # 每次加载4个样本\n",
    "    shuffle=False,  # 不打乱测试数据顺序\n",
    "    num_workers=2   # 使用两个子进程来加载数据\n",
    ")\n",
    "\n",
    "# 定义数据集的类别名称\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 定义 CNN 模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # 第一个卷积层，输入通道3，输出通道6，卷积核大小5\n",
    "        self.pool = nn.MaxPool2d(2, 2)   # 最大池化层，窗口大小2，步长2\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 第二个卷积层，输入通道6，输出通道16，卷积核大小5\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 第一个全连接层，输入特征数16*5*5，输出120\n",
    "        self.fc2 = nn.Linear(120, 84)     # 第二个全连接层，输入120，输出84\n",
    "        self.fc3 = nn.Linear(84, 10)      # 第三个全连接层，输入84，输出10（类别数）\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 应用第一个卷积层，激活函数ReLU，然后池化\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 应用第二个卷积层，激活函数ReLU，然后池化\n",
    "        x = x.view(-1, 16 * 5 * 5)           # 将张量展平为一维向量\n",
    "        x = F.relu(self.fc1(x))              # 应用第一个全连接层和ReLU激活\n",
    "        x = F.relu(self.fc2(x))              # 应用第二个全连接层和ReLU激活\n",
    "        x = self.fc3(x)                      # 应用第三个全连接层（输出层）\n",
    "        return x\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")  # 输出当前使用的设备（CPU或GPU）\n",
    "\n",
    "net = Net().to(device)  # 创建模型实例并移动到 GPU 上\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 使用交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  # 使用随机梯度下降优化器\n",
    "\n",
    "# 计时开始\n",
    "start_time = time.time()\n",
    "\n",
    "# 记录每个周期的准确率和损失\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(30):  # 训练30个周期\n",
    "    running_loss = 0.0  # 初始化运行损失\n",
    "    correct = 0         # 初始化正确预测计数\n",
    "    total = 0           # 初始化总样本计数\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data  # 获取输入数据和标签\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # 将数据移动到 GPU 上\n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        outputs = net(inputs)  # 前向传播\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        \n",
    "        running_loss += loss.item()  # 累加损失\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 获取预测结果\n",
    "        total += labels.size(0)  # 累加总样本数\n",
    "        correct += (predicted == labels).sum().item()  # 累加正确预测数\n",
    "    \n",
    "    # 记录训练准确率和损失\n",
    "    train_loss = running_loss / (i + 1)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # 输出每个周期的损失和准确率\n",
    "    print(f'Epoch {epoch + 1}, Loss: {train_loss}, Accuracy: {train_accuracy}%')\n",
    "\n",
    "print('Finished Training')  # 提示训练完成\n",
    "\n",
    "# 计时结束\n",
    "end_time = time.time()\n",
    "\n",
    "# 测试模型\n",
    "correct = 0  # 初始化正确预测计数\n",
    "total = 0    # 初始化总样本计数\n",
    "class_correct = list(0. for i in range(10))  # 每个类别的正确预测计数\n",
    "class_total = list(0. for i in range(10))    # 每个类别的总样本计数\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for data in testloader:\n",
    "        images, labels = data  # 获取测试数据和标签\n",
    "        images, labels = images.to(device), labels.to(device)  # 将数据移动到 GPU 上\n",
    "        outputs = net(images)  # 前向传播\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 获取预测结果\n",
    "        total += labels.size(0)  # 累加总样本数\n",
    "        correct += (predicted == labels).sum().item()  # 累加正确预测数\n",
    "        \n",
    "        # 统计每个类别的正确预测和总样本数\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "# 记录测试准确率\n",
    "test_accuracy = 100 * correct / total\n",
    "test_accuracies.append(test_accuracy)\n",
    "\n",
    "# 输出测试准确率\n",
    "print(f'Test Accuracy: {test_accuracy}%')\n",
    "\n",
    "# 输出每个类别的准确率\n",
    "for i in range(10):\n",
    "    if class_total[i] != 0:\n",
    "        print(f'Accuracy of {classes[i]} : {100 * class_correct[i] / class_total[i]}%')\n",
    "    else:\n",
    "        print(f'Accuracy of {classes[i]}: 0% (No samples in test set)')\n",
    "\n",
    "# 输出训练时间\n",
    "print(f'Training Time: {(end_time - start_time):.2f} seconds')\n",
    "\n",
    "# 绘制训练和测试准确率图表\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36811a46-b4b2-48df-8666-447ee13bcbed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
